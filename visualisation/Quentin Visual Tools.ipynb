{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_raw_data = False\n",
    "if load_raw_data:\n",
    "    brain_masks = np.load('../data/all_2016_2017/brain_masks.npy')\n",
    "    clinical_inputs = np.load('../data/all_2016_2017/clinical_inputs.npy')\n",
    "    ids = np.load('../data/all_2016_2017/ids.npy')\n",
    "    included_subjects = np.load('../data/all_2016_2017/included_subjects.npy') # empty\n",
    "    params = np.load('../data/all_2016_2017/params.npy') # inaccessible\n",
    "\n",
    "    # Heavy\n",
    "    lesion_GT = np.load('../data/all_2016_2017/lesion_GT.npy')\n",
    "    ct_inputs = np.load('../data/all_2016_2017/ct_inputs.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le volume dans le lecteur D s'appelle Data\n",
      " Le num‚ro de s‚rie du volume est DC28-9704\n",
      "\n",
      " R‚pertoire de D:\\GitHub\\StrokeLesionPredict-BIO503\\PerfusionCT-Net\n",
      "\n",
      "10/06/2020  12:05    <DIR>          .\n",
      "10/06/2020  12:05    <DIR>          ..\n",
      "01/06/2020  12:46             1ÿ985 .gitignore\n",
      "09/06/2020  19:21    <DIR>          .ipynb_checkpoints\n",
      "09/06/2020  13:56             5ÿ314 augmentation_vis.py\n",
      "09/06/2020  14:25    <DIR>          checkpoints\n",
      "09/06/2020  14:06    <DIR>          configs\n",
      "01/06/2020  22:29    <DIR>          dataio\n",
      "01/06/2020  12:46             1ÿ558 journal.md\n",
      "08/06/2020  15:20    <DIR>          models\n",
      "10/06/2020  12:05             8ÿ806 Quentin Visual Tools.ipynb\n",
      "08/06/2020  15:20             1ÿ335 README.md\n",
      "08/06/2020  15:20               381 requirements.txt\n",
      "08/06/2020  15:25               648 requirements_gsp.txt\n",
      "09/06/2020  19:24    <DIR>          src\n",
      "01/06/2020  22:29    <DIR>          static\n",
      "08/06/2020  15:25             6ÿ709 train_segmentation.py\n",
      "09/06/2020  19:27         2ÿ113ÿ401 tutorial_1_visualization.ipynb\n",
      "08/06/2020  15:20    <DIR>          utils\n",
      "               9 fichier(s)        2ÿ140ÿ137 octets\n",
      "              10 R‚p(s)  127ÿ024ÿ750ÿ592 octets libres\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python train_segmentation.py -c D:/GitHub/StrokeLesionPredict-BIO503/PerfusionCT-Net/configs/small_dataset_config_unet_pct_multi_att_dsv.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\python\\anaconda3\\envs\\pctnet\\lib\\site-packages\\torchio\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import torchio\n",
    "print(torchio.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import json_file_to_pyobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataio.loaders.geneva_stroke_dataset_pCT.GenevaStrokeDataset_pCT"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dataset('gsd_pCT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataio.loaders import get_dataset\n",
    "from dataio.transformation import get_dataset_transformation\n",
    "\n",
    "from models import get_model\n",
    "from utils import utils\n",
    "from utils.utils import json_file_to_pyobj\n",
    "\n",
    "\n",
    "import torchio\n",
    "\n",
    "print(torchio.__file__)\n",
    "\n",
    "\"\"\"\n",
    "Notes:\n",
    "shift is working\n",
    "rotation is working\n",
    "noise is working\n",
    "\n",
    "rot + shift takes wrong interpolation for mask\n",
    "skewing introduces weird artifacts, same with scaling\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# todo images need to be in form X,Y,Z\n",
    "def aug_vis(json_filename):\n",
    "    # Visualisation arguments\n",
    "    with_mask = True\n",
    "    len_x = 5  # number of images on x-axis for vis pdf\n",
    "    len_y = 5  # number of images on y-axis for vis pdf\n",
    "    nbr_pages = 10\n",
    "    total_images = len_x * len_y * nbr_pages  # total number of slices that will be augmented\n",
    "\n",
    "    # Load options\n",
    "    json_opts = json_file_to_pyobj(json_filename)\n",
    "    train_opts = json_opts.training\n",
    "\n",
    "    # Architecture type\n",
    "    arch_type = train_opts.arch_type\n",
    "\n",
    "    # Setup Dataset and Augmentation\n",
    "    ds_class = get_dataset('gsd_pCT')\n",
    "    ds_path = json_opts.data.data_dir\n",
    "    template_path = json_opts.data.template_dir\n",
    "    ds_transform = get_dataset_transformation('mlebe', opts=json_opts.augmentation,\n",
    "                                              max_output_channels=json_opts.model.output_nc)\n",
    "\n",
    "    # Setup channels\n",
    "    channels = json_opts.data_opts.channels\n",
    "    if len(channels) != json_opts.model.input_nc \\\n",
    "            or len(channels) != getattr(json_opts.augmentation, 'mlebe').scale_size[-1]:\n",
    "        raise Exception(\n",
    "            'Number of data channels must match number of model channels, and patch and scale size dimensions')\n",
    "\n",
    "    # Setup Data Loader\n",
    "    split_opts = json_opts.data_split\n",
    "    train_dataset = ds_class(template_path, ds_path, json_opts.data, split='train',\n",
    "                             transform=ds_transform['train'],\n",
    "                             train_size=split_opts.train_size, test_size=split_opts.test_size,\n",
    "                             valid_size=split_opts.validation_size, split_seed=split_opts.seed)\n",
    "\n",
    "    train_dataset.selection = train_dataset.selection[:(total_images // 96) * 3]\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, num_workers=16, batch_size=train_opts.batchSize, shuffle=True)\n",
    "\n",
    "    save_dir = os.path.join('visualisation', json_opts.model.experiment_name)\n",
    "    utils.rm_and_mkdir(save_dir)\n",
    "\n",
    "    slices = []\n",
    "    masks = []\n",
    "\n",
    "    for epoch_iter, (images, labels, indices) in tqdm(enumerate(train_loader, 1),\n",
    "                                                      total=len(train_loader)):\n",
    "        if epoch_iter <= total_images:\n",
    "\n",
    "            images = images.numpy()\n",
    "            labels = labels.numpy()\n",
    "\n",
    "            for image_idx in range(images.shape[0]):\n",
    "                image = np.squeeze(images[image_idx])\n",
    "                label = np.squeeze(labels[image_idx])\n",
    "                for slice in range(image.shape[2]):\n",
    "                    if not np.max(image[..., slice]) <= 0:\n",
    "                        slices.append(image[..., slice])\n",
    "                        masks.append(label[..., slice])\n",
    "\n",
    "    temp = list(zip(slices, masks))\n",
    "\n",
    "    random.shuffle(temp)\n",
    "\n",
    "    slices, masks = zip(*temp)\n",
    "    list_index = 1\n",
    "    with PdfPages(save_dir + '/augm_img_vis.pdf') as pdf:\n",
    "        for page in range(nbr_pages):\n",
    "            plt.figure()\n",
    "            plt.figtext(.05, .9, str(json_opts.augmentation.mlebe), fontsize=4)\n",
    "            idx = 1\n",
    "            for slice in range(len_x * len_y):\n",
    "                plt.subplot(len_y, len_x, idx)\n",
    "                plt.imshow(slices[list_index], cmap='gray')\n",
    "                if with_mask:\n",
    "                    plt.imshow(masks[list_index], cmap='Blues', alpha=0.4)\n",
    "                plt.axis('off')\n",
    "                idx += 1\n",
    "                list_index += 1\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "\n",
    "    list_index = 1\n",
    "    with PdfPages(save_dir + '/augm_mask_vis.pdf') as pdf:\n",
    "        for page in range(nbr_pages):\n",
    "            plt.figure()\n",
    "            plt.figtext(.05, .9, str(json_opts.augmentation.mlebe), fontsize=4)\n",
    "            idx = 1\n",
    "            for slice in range(len_x * len_y):\n",
    "                plt.subplot(len_y, len_x, idx)\n",
    "                plt.imshow(masks[list_index], cmap='gray')\n",
    "                plt.axis('off')\n",
    "                idx += 1\n",
    "                list_index += 1\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "config_paths = ['/home/hendrik/src/MLEBE/mlebe/threed/training/configs/augm_tries/elastic.json',\n",
    "                '/home/hendrik/src/MLEBE/mlebe/threed/training/configs/augm_tries/rotation.json',\n",
    "                '/home/hendrik/src/MLEBE/mlebe/threed/training/configs/augm_tries/shift.json',\n",
    "                '/home/hendrik/src/MLEBE/mlebe/threed/training/configs/augm_tries/flip.json',\n",
    "                '/home/hendrik/src/MLEBE/mlebe/threed/training/configs/augm_tries/noise.json',\n",
    "                '/home/hendrik/src/MLEBE/mlebe/threed/training/configs/try_augm.json']\n",
    "\n",
    "# config_paths = [\n",
    "#     '/home/hendrik/src/MLEBE/mlebe/threed/training/configs/try_augm.json',\n",
    "# ]\n",
    "for config_path in config_paths:\n",
    "    aug_vis(config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
