{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from dataio.transformation.imageTransformations import RandomFlipTransform, RandomElasticTransform, RandomAffineTransform, RandomNoiseTransform\n",
    "from dataio.transformation.imageTransformations import StandardizeImage\n",
    "from gsprep.visual_tools.visual import display, display_4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_path = \"D:/GitHub/StrokeLesionPredict-BIO503/data/working_data/pct_unet_all_2016_2017/rescaled_data_set.npz\"\n",
    "channel = 0\n",
    "subj_id = None\n",
    "subj = 0\n",
    "ids = np.load(dataset_path, allow_pickle=True)['ids']\n",
    "if subj_id is not None:\n",
    "    subj = np.argwhere(ids==subj_id)[0, 0]\n",
    "\n",
    "raw_images = np.load(dataset_path, allow_pickle=True)['ct_inputs'][subj][..., 0:4].astype(np.float64)\n",
    "try:\n",
    "    raw_labels = np.load(dataset_path, allow_pickle=True)['ct_lesion_GT'][subj].astype(np.float64)\n",
    "except:\n",
    "    raw_labels = np.load(dataset_path, allow_pickle=True)['lesion_GT'][subj].astype(np.float64)\n",
    "raw_mask = np.load(dataset_path, allow_pickle=True)['brain_masks'][subj]\n",
    "\n",
    "raw_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_4D(raw_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(raw_images[..., 0], raw_mask)\n",
    "display(raw_images[..., 1], raw_mask)\n",
    "display(raw_images[..., 2], raw_mask)\n",
    "display(raw_images[..., 3], raw_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# images, labels = torch.from_numpy(np.expand_dims(raw_images, axis=-1)), \\\n",
    "#                  torch.from_numpy(np.expand_dims(raw_labels, axis=-1))\n",
    "images, labels = torch.from_numpy(raw_images), \\\n",
    "                 torch.from_numpy(np.expand_dims(raw_labels, axis=-1))\n",
    "\n",
    "\n",
    "seed = 7533\n",
    "max_output_channels = 2\n",
    "print(images.shape)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "flip_axis = (1)\n",
    "random_flip_prob = 1\n",
    "flip = RandomFlipTransform(axes=flip_axis, flip_probability=1, p=random_flip_prob, seed=seed, max_output_channels=max_output_channels)\n",
    "print(images.numpy().shape)\n",
    "print(labels.numpy().shape)\n",
    "flipped_image, flipped_label = flip(images, labels)\n",
    "\n",
    "display(images.numpy()[..., 0], mask=labels.numpy())\n",
    "\n",
    "print(flipped_image.numpy().shape)\n",
    "print(flipped_label.numpy().shape)\n",
    "display(flipped_image.numpy()[..., 0], mask=flipped_label.numpy())\n",
    "display(flipped_image.numpy()[..., 1], mask=flipped_label.numpy())\n",
    "display(flipped_image.numpy()[..., 2], mask=flipped_label.numpy())\n",
    "display(flipped_image.numpy()[..., 3], mask=flipped_label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "elastic = RandomElasticTransform(max_displacement=[12, 12, 0],\n",
    "                                   num_control_points=(7, 7, 7),\n",
    "                                   image_interpolation='bspline',\n",
    "                                   seed=seed, p=1,\n",
    "                                   max_output_channels=max_output_channels, verbose=True)\n",
    "\n",
    "elastic_image, elastic_label = elastic(images, labels)\n",
    "\n",
    "plt.imshow(elastic_image.numpy()[..., 45, 0], cmap='gray')\n",
    "plt.imshow(elastic_label.numpy()[..., 45, 0], cmap='Blues', alpha=0.4)\n",
    "\n",
    "display(images.numpy()[..., 0], mask=labels.numpy())\n",
    "display(elastic_image.numpy()[..., 0], mask=elastic_label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shift_val = (0, 0)  # translation range\n",
    "rotate_val = 0  # rotation range\n",
    "scale_val = (1.6, 1.6) # scaling range\n",
    "\n",
    "affine = RandomAffineTransform(scales=scale_val, degrees=rotate_val, translation=shift_val,\n",
    "                                  isotropic=True, default_pad_value=0,\n",
    "                                  image_interpolation='bspline', seed=seed, p=1,\n",
    "                                  max_output_channels=max_output_channels, verbose=True)\n",
    "\n",
    "affine_image, affine_label = affine(images, labels)\n",
    "\n",
    "#display(images.numpy()[..., 0], mask=labels.numpy())\n",
    "display(affine_image.numpy()[..., 0], mask=affine_label.numpy())\n",
    "plt.imshow(affine_image.numpy()[..., 35, 0], cmap='gray')\n",
    "plt.imshow(affine_label.numpy()[..., 35, 0], cmap='Blues', alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shift_val = (0, 0)  # translation range\n",
    "rotate_val = (5, 5)  # rotation range\n",
    "scale_val = (1.8, 1.8) # scaling range\n",
    "\n",
    "affine = RandomAffineTransform(scales=scale_val, degrees=rotate_val, translation=shift_val,\n",
    "                                  isotropic=True, default_pad_value=0,\n",
    "                                  image_interpolation='bspline', seed=seed, p=1,\n",
    "                                  max_output_channels=max_output_channels, verbose=True)\n",
    "\n",
    "affine_image, affine_label = affine(images, labels)\n",
    "\n",
    "#display(images.numpy()[..., 0], mask=labels.numpy())\n",
    "display(affine_image.numpy()[..., 0], mask=affine_label.numpy())\n",
    "plt.imshow(affine_image.numpy()[..., 35, 0], cmap='gray')\n",
    "plt.imshow(affine_label.numpy()[..., 35, 0], cmap='Blues', alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_unique = 10\n",
    "shift_val = 10 # (shift_unique, shift_unique)  # translation range\n",
    "rotate_val = (0, 0)  # rotation range\n",
    "scale_val = (1.0, 1.0) # scaling range\n",
    "\n",
    "affine = RandomAffineTransform(scales=scale_val, degrees=rotate_val, translation=shift_val,\n",
    "                                  isotropic=True, default_pad_value=0,\n",
    "                                  image_interpolation='bspline', seed=54, p=1,\n",
    "                                  max_output_channels=max_output_channels, verbose=True)\n",
    "\n",
    "affine_image, affine_label = affine(images, labels)\n",
    "\n",
    "#display(images.numpy()[..., 0], mask=labels.numpy())\n",
    "display(affine_image.numpy()[..., 0], mask=affine_label.numpy())\n",
    "plt.imshow(affine_image.numpy()[..., 35, 0], cmap='gray')\n",
    "plt.imshow(affine_label.numpy()[..., 35, 0], cmap='Blues', alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "noise_mean = np.mean(raw_images[raw_mask]) # find appropriate mean by taking mean of masked image\n",
    "print('Mean of input image:', noise_mean)\n",
    "noise_std = (0.75, 0.75)  # range of noise std\n",
    "\n",
    "noise = RandomNoiseTransform(mean=noise_mean, std=noise_std, seed=seed, p=1,\n",
    "                                 max_output_channels=max_output_channels)\n",
    "\n",
    "noise_image, noise_label = noise(images, labels)\n",
    "\n",
    "display(images.numpy()[..., 0], mask=labels.numpy())\n",
    "display(noise_image.numpy()[..., 0], mask=noise_label.numpy())\n",
    "plt.imshow(noise_image.numpy()[..., 35, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check that the masks are the same at the output of the Noise function. (must be 0)\n",
    "79*95*79 - torch.eq(labels, noise_label).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dataio.transformation.imageTransformations import StandardizeImage\n",
    "\n",
    "norm = StandardizeImage(norm_flag=[True, True, True, False])\n",
    "\n",
    "\n",
    "norm_image, norm_label = norm(images, labels)\n",
    "\n",
    "display(images.numpy()[..., 0], mask=labels.numpy())\n",
    "display(norm_image.numpy()[..., 0], mask=labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the masks are the same at the output of the NormalizeImage function. (must be 0)\n",
    "79*95*79 - torch.eq(labels, norm_label).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Image Global Mean : \\t\\t\", images.mean().item())\n",
    "print(\"Standardized Global Mean : \\t\", norm_image.mean().item())\n",
    "\n",
    "print(\"\\nImage Global StD : \\t\\t\", images.std().item())\n",
    "print(\"Standardized Global StD : \\t\", norm_image.std().item())\n",
    "\n",
    "print(\"\\nChannel 0\")\n",
    "print(\"Channel 0 Mean : \\t\\t\", images[..., 0].mean().item())\n",
    "print(\"Standardized Channel 0 Mean : \\t\", norm_image[..., 0].mean().item())\n",
    "print(\"Channel 0 StD : \\t\\t\", images[..., 0].std().item())\n",
    "print(\"Standardized Channel 0 StD : \\t\", norm_image[..., 0].std().item())\n",
    "\n",
    "print(\"\\nChannel 1\")\n",
    "print(\"Channel 1 Mean : \\t\\t\", images[..., 1].mean().item())\n",
    "print(\"Standardized Channel 1 Mean : \\t\", norm_image[..., 1].mean().item())\n",
    "print(\"Channel 1 StD : \\t\\t\", images[..., 1].std().item())\n",
    "print(\"Standardized Channel 1 StD : \\t\", norm_image[..., 1].std().item())\n",
    "\n",
    "print(\"\\nAnd so on...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':100})\n",
    "\n",
    "exp_names = [\"Tmax\", \"CBF\", \"MTT\", \"CBV\"]\n",
    "exp_considered = 0\n",
    "\n",
    "# Plot Histogram on Initial Image\n",
    "plt.hist(images[..., exp_considered].numpy().flatten(), bins=100)\n",
    "plt.gca().set(title='Original Image '+exp_names[exp_considered]+' Histogram', xlabel='Pixel Value', ylabel='Count')\n",
    "\n",
    "print(\"Max : \", np.max(images[..., exp_considered].numpy().flatten()))\n",
    "print(\"Min : \", np.min(images[..., exp_considered].numpy().flatten()))\n",
    "print(\"Mean : \", np.mean(images[..., exp_considered].numpy().flatten()))\n",
    "print(\"Std : \", np.std(images[..., exp_considered].numpy().flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_names = [\"Tmax\", \"CBF\", \"MTT\", \"CBV\"]\n",
    "exp_considered = 0\n",
    "\n",
    "# Plot Histogram on Normalized Image\n",
    "plt.hist(norm_image[..., exp_considered].numpy().flatten(), bins=100)\n",
    "plt.gca().set(title='Standardized Image '+exp_names[exp_considered]+' Histogram', xlabel='Pixel Value', ylabel='Count')\n",
    "\n",
    "print(\"Max : \", np.max(norm_image[..., exp_considered].numpy().flatten()))\n",
    "print(\"Min : \", np.min(norm_image[..., exp_considered].numpy().flatten()))\n",
    "print(\"Mean : \", np.mean(norm_image[..., exp_considered].numpy().flatten()))\n",
    "print(\"Std : \", np.std(norm_image[..., exp_considered].numpy().flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsample.transforms as ts\n",
    "chanfirst = ts.ChannelsFirst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chanf_image, chanf_label = chanfirst(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chanf_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = ts.Pad(size=[96,96,96,1])\n",
    "pad_image, pad_label = pad(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_val = 100  # translation range\n",
    "rotate_val = (5, 5)  # rotation range\n",
    "scale_val = (1.8, 1.8) # scaling range\n",
    "\n",
    "affine = RandomAffineTransform(scales=scale_val, degrees=rotate_val, translation=shift_val,\n",
    "                                  isotropic=True, default_pad_value=0,\n",
    "                                  image_interpolation='bspline', seed=32, p=1,\n",
    "                                  max_output_channels=max_output_channels, verbose=True)\n",
    "\n",
    "affine_image, affine_label = affine(images, labels)\n",
    "\n",
    "display(images.numpy()[..., 0], mask=labels.numpy())\n",
    "display(affine_image.numpy()[..., 0], mask=affine_label.numpy())\n",
    "plt.imshow(affine_image.numpy()[..., 35, 0], cmap='gray')\n",
    "plt.imshow(affine_label.numpy()[..., 35, 0], cmap='Blues', alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse input arguments\n",
    "json_filename = arguments.config\n",
    "\n",
    "# Load options\n",
    "json_opts = json_file_to_pyobj(json_filename)\n",
    "train_opts = json_opts.training\n",
    "\n",
    "# Architecture type\n",
    "arch_type = train_opts.arch_type\n",
    "\n",
    "# Setup Dataset and Augmentation\n",
    "ds_class = get_dataset(arch_type)\n",
    "ds_path = get_dataset_path(arch_type, json_opts.data_path)\n",
    "ds_transform = get_dataset_transformation(arch_type, opts=json_opts.augmentation,\n",
    "                                          max_output_channels=json_opts.model.output_nc)\n",
    "\n",
    "# Setup channels\n",
    "channels = json_opts.data_opts.channels\n",
    "if len(channels) != json_opts.model.input_nc :\n",
    "        # or len(channels) != getattr(json_opts.augmentation, arch_type).scale_size[-1]:\n",
    "    raise Exception('Number of data channels must match number of model channels, and patch and scale size dimensions')\n",
    "\n",
    "# Setup the NN Model\n",
    "model = get_model(json_opts.model)\n",
    "if network_debug:\n",
    "    print('# of pars: ', model.get_number_parameters())\n",
    "    print('fp time: {0:.3f} sec\\tbp time: {1:.3f} sec per sample'.format(*model.get_fp_bp_time()))\n",
    "    exit()\n",
    "\n",
    "# Setup Data Loader\n",
    "split_opts = json_opts.data_split\n",
    "train_dataset = ds_class(ds_path, split='train',      transform=ds_transform['train'], preload_data=train_opts.preloadData,\n",
    "                         train_size=split_opts.train_size, test_size=split_opts.test_size,\n",
    "                         valid_size=split_opts.validation_size, split_seed=split_opts.seed, channels=channels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
